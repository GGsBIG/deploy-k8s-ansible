# å®Œæ•´ ELK Stack éƒ¨ç½²æŒ‡å— (HTTPSç‰ˆæœ¬)

## æ¦‚è¿°

æœ¬æŒ‡å—å°‡å®Œæ•´éƒ¨ç½² ELK Stack (Elasticsearch + Kibana + Filebeat)ï¼ŒåŒ…å«ï¼š
- âœ… çµ±ä¸€éƒ¨ç½²åœ¨ `elk-stack` namespace
- âœ… HTTPS å®‰å…¨é€£æ¥
- âœ… è‡ªå®šç¾©å¸³è™Ÿ `admin/Systex123!`
- âœ… Kibana URL: `https://172.21.169.71:5601`
- âœ… Filebeat æ—¥èªŒæ”¶é›†
- âœ… LoadBalancer å’Œ Ingress é…ç½®

### æ¶æ§‹åœ–
```
Kubernetes Pods --> Filebeat --> Elasticsearch --> Kibana (HTTPS)
     æ—¥èªŒæ”¶é›†          è™•ç†è½‰ç™¼        å­˜å„²ç´¢å¼•        è¦–è¦ºåŒ–åˆ†æ
                                                   â†“
                                            LoadBalancer
                                         https://172.21.169.71:5601
```

---

## ç¬¬1æ­¥ï¼šç’°å¢ƒæº–å‚™

### 1.1 å‰µå»ºçµ±ä¸€ Namespace

```bash
# 1. å‰µå»º elk-stack namespace
kubectl create namespace elk-stack

# 2. è¨­ç½®é è¨­ namespaceï¼ˆå¯é¸ï¼‰
kubectl config set-context --current --namespace=elk-stack

# 3. é©—è­‰ namespace å‰µå»º
kubectl get namespaces | grep elk-stack
```

### 1.2 å‰µå»º MetalLB IP é…ç½®

```bash
# 1. å‰µå»º Kibana å°ˆç”¨ IP é…ç½®
cat > metallb-kibana-config.yaml << 'EOF'
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: kibana-pool
  namespace: metallb-system
spec:
  addresses:
  - 172.21.169.71/32
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: kibana-advertisement
  namespace: metallb-system
spec:
  ipAddressPools:
  - kibana-pool
EOF

# 2. æ‡‰ç”¨ MetalLB é…ç½®
kubectl apply -f metallb-kibana-config.yaml

# 3. é©—è­‰ IP æ± é…ç½®
kubectl get ipaddresspool -n metallb-system | grep kibana
kubectl get l2advertisement -n metallb-system | grep kibana
```

---

## ç¬¬2æ­¥ï¼šéƒ¨ç½² ECK Operator

### 2.1 å®‰è£ ECK Operator

```bash
# 1. å‰µå»º ECK namespace
kubectl create namespace elastic-system

# 2. å®‰è£ ECK CRDs
kubectl apply -f https://download.elastic.co/downloads/eck/2.9.0/crds.yaml

# 3. å®‰è£ ECK Operator
kubectl apply -f https://download.elastic.co/downloads/eck/2.9.0/operator.yaml

# 4. ç­‰å¾… Operator å°±ç·’
kubectl wait --for=condition=ready pod -l control-plane=elastic-operator -n elastic-system --timeout=300s

# 5. é©—è­‰ ECK Operator ç‹€æ…‹
kubectl get pods -n elastic-system
kubectl logs -n elastic-system statefulset/elastic-operator --tail=10
```

---

## ç¬¬3æ­¥ï¼šéƒ¨ç½² Elasticsearch

### 3.1 å‰µå»º Elasticsearch é…ç½®

```bash
# 1. å‰µå»º Elasticsearch éƒ¨ç½²é…ç½®
cat > elasticsearch.yaml << 'EOF'
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: elasticsearch
  namespace: elk-stack
spec:
  version: 8.5.1
  http:
    tls:
      selfSignedCertificate:
        disabled: false
  nodeSets:
  - name: master
    count: 1
    config:
      # å®‰å…¨æ€§é…ç½®
      xpack.security.enabled: true
      xpack.security.transport.ssl.enabled: true
      xpack.security.http.ssl.enabled: true
      # è¨˜æ†¶é«”æ˜ å°„è¨­å®š
      node.store.allow_mmap: false
      # å¢é›†è¨­å®š
      cluster.initial_master_nodes: ["elasticsearch-es-master-0"]
      discovery.seed_hosts: ["elasticsearch-es-master"]
    podTemplate:
      metadata:
        labels:
          app: elasticsearch
      spec:
        # è¨­å®šå®‰å…¨ä¸Šä¸‹æ–‡
        securityContext:
          fsGroup: 1000
        # åˆå§‹åŒ–å®¹å™¨
        initContainers:
        - name: increase-vm-max-map-count
          image: busybox:1.35
          command: ['sysctl', '-w', 'vm.max_map_count=262144']
          securityContext:
            privileged: true
        - name: increase-fd-ulimit
          image: busybox:1.35
          command: ['sh', '-c', 'ulimit -n 65536']
          securityContext:
            privileged: true
        containers:
        - name: elasticsearch
          env:
          - name: ES_JAVA_OPTS
            value: "-Xms2g -Xmx2g"
          resources:
            requests:
              memory: 2Gi
              cpu: 1000m
            limits:
              memory: 4Gi
              cpu: 2000m
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 50Gi
        storageClassName: nfs-storage
EOF

# 2. éƒ¨ç½² Elasticsearch
kubectl apply -f elasticsearch.yaml

# 3. ç­‰å¾… Elasticsearch å°±ç·’
echo "ç­‰å¾… Elasticsearch Pod å‰µå»º..."
for i in {1..30}; do
    STATUS=$(kubectl get pod elasticsearch-es-master-0 -n elk-stack -o jsonpath='{.status.phase}' 2>/dev/null || echo "NotFound")
    READY=$(kubectl get pod elasticsearch-es-master-0 -n elk-stack -o jsonpath='{.status.containerStatuses[0].ready}' 2>/dev/null || echo "false")
    
    echo "Elasticsearch æª¢æŸ¥ $i/30: Status=$STATUS, Ready=$READY"
    
    if [ "$STATUS" = "Running" ] && [ "$READY" = "true" ]; then
        echo "âœ… Elasticsearch å·²æˆåŠŸå•Ÿå‹•"
        break
    fi
    
    if [ $i -eq 30 ]; then
        echo "âŒ Elasticsearch å•Ÿå‹•è¶…æ™‚"
        kubectl describe pod elasticsearch-es-master-0 -n elk-stack
        kubectl logs elasticsearch-es-master-0 -n elk-stack --tail=20
        exit 1
    fi
    
    sleep 20
done
```

### 3.2 å‰µå»º admin ç”¨æˆ¶

```bash
# 1. å–å¾— ECK è‡ªå‹•ç”Ÿæˆçš„ elastic è¶…ç´šç”¨æˆ¶å¯†ç¢¼
ELASTIC_PASSWORD=$(kubectl get secret elasticsearch-es-elastic-user -n elk-stack -o go-template='{{.data.elastic | base64decode}}')
echo "ECK Elasticsearch è¶…ç´šç”¨æˆ¶å¯†ç¢¼: $ELASTIC_PASSWORD"

# 2. ç­‰å¾… Elasticsearch å®Œå…¨å°±ç·’
sleep 60

# 3. åœ¨ Elasticsearch ä¸­å‰µå»º admin ç”¨æˆ¶
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -X POST "https://localhost:9200/_security/user/admin" \
  -H "Content-Type: application/json" \
  -u "elastic:$ELASTIC_PASSWORD" \
  -d '{
    "password": "Systex123!",
    "roles": ["superuser", "kibana_admin", "kibana_user"],
    "full_name": "Administrator",
    "email": "admin@example.com"
  }'

# 4. é©—è­‰ admin ç”¨æˆ¶å‰µå»ºæˆåŠŸ
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -X GET "https://localhost:9200/_security/user/admin" \
  -u "elastic:$ELASTIC_PASSWORD"

# 5. æ¸¬è©¦ admin ç”¨æˆ¶èªè­‰
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -u "admin:Systex123!" \
  https://localhost:9200/_cluster/health?pretty

echo "âœ… admin ç”¨æˆ¶å‰µå»ºæˆåŠŸï¼Œå¯†ç¢¼: Systex123!"
```

---

## ç¬¬4æ­¥ï¼šéƒ¨ç½² Kibana

### 4.1 å‰µå»º Kibana é…ç½®

```bash
# 1. å‰µå»º Kibana éƒ¨ç½²é…ç½®
cat > kibana.yaml << 'EOF'
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: kibana
  namespace: elk-stack
spec:
  version: 8.5.1
  count: 1
  elasticsearchRef:
    name: elasticsearch
    namespace: elk-stack
  http:
    service:
      spec:
        type: LoadBalancer
        loadBalancerIP: "172.21.169.71"
        ports:
        - name: https
          port: 5601
          targetPort: 5601
          protocol: TCP
      metadata:
        annotations:
          metallb.universe.tf/loadBalancerIPs: "172.21.169.71"
    tls:
      selfSignedCertificate:
        disabled: false
  podTemplate:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        env:
        - name: NODE_OPTIONS
          value: "--max-old-space-size=1800"
        resources:
          requests:
            memory: 1Gi
            cpu: 500m
          limits:
            memory: 2Gi
            cpu: 1000m
  config:
    server.host: "0.0.0.0"
    server.port: 5601
    server.publicBaseUrl: "https://172.21.169.71:5601"
    # Elasticsearch é…ç½®
    elasticsearch.ssl.verificationMode: certificate
EOF

# 2. éƒ¨ç½² Kibana
kubectl apply -f kibana.yaml

# 3. ç­‰å¾… Kibana å°±ç·’
echo "ç­‰å¾… Kibana Pod å‰µå»º..."
for i in {1..40}; do
    POD_NAME=$(kubectl get pods -n elk-stack -l kibana.k8s.elastic.co/name=kibana -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "NotFound")
    
    if [ "$POD_NAME" = "NotFound" ]; then
        echo "Kibana æª¢æŸ¥ $i/40: Pod å°šæœªå‰µå»º"
    else
        STATUS=$(kubectl get pod $POD_NAME -n elk-stack -o jsonpath='{.status.phase}' 2>/dev/null || echo "Unknown")
        READY=$(kubectl get pod $POD_NAME -n elk-stack -o jsonpath='{.status.containerStatuses[0].ready}' 2>/dev/null || echo "false")
        
        echo "Kibana æª¢æŸ¥ $i/40: Pod=$POD_NAME, Status=$STATUS, Ready=$READY"
        
        if [ "$STATUS" = "Running" ] && [ "$READY" = "true" ]; then
            echo "âœ… Kibana å·²æˆåŠŸå•Ÿå‹•"
            break
        fi
        
        if [ "$STATUS" = "Error" ] || [ "$STATUS" = "CrashLoopBackOff" ]; then
            echo "âŒ Kibana éŒ¯èª¤ç‹€æ…‹ï¼Œé¡¯ç¤ºæ—¥èªŒ:"
            kubectl logs $POD_NAME -n elk-stack --tail=10
        fi
    fi
    
    if [ $i -eq 40 ]; then
        echo "âŒ Kibana å•Ÿå‹•è¶…æ™‚"
        kubectl describe pod $POD_NAME -n elk-stack
        exit 1
    fi
    
    sleep 15
done

# 4. æª¢æŸ¥ LoadBalancer æœå‹™
kubectl get svc kibana-kb-http -n elk-stack
```

---

## ç¬¬5æ­¥ï¼šéƒ¨ç½² Filebeat

### 5.1 å‰µå»º Filebeat RBAC

```bash
# 1. å‰µå»º Filebeat ServiceAccount å’Œ RBAC æ¬Šé™
cat > filebeat-rbac.yaml << 'EOF'
apiVersion: v1
kind: ServiceAccount
metadata:
  name: filebeat
  namespace: elk-stack
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: filebeat
rules:
- apiGroups: [""]
  resources:
  - nodes
  - namespaces
  - events
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups: ["extensions"]
  resources:
  - replicasets
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources:
  - statefulsets
  - deployments
  - replicasets
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
  - nodes/stats
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: filebeat
subjects:
- kind: ServiceAccount
  name: filebeat
  namespace: elk-stack
roleRef:
  kind: ClusterRole
  name: filebeat
  apiGroup: rbac.authorization.k8s.io
EOF

# 2. æ‡‰ç”¨ RBAC é…ç½®
kubectl apply -f filebeat-rbac.yaml

# 3. é©—è­‰ RBAC å‰µå»º
kubectl get sa filebeat -n elk-stack
kubectl get clusterrole filebeat
```

### 5.2 å‰µå»º Filebeat é…ç½®

```bash
# 1. å‰µå»º Filebeat ConfigMap
cat > filebeat-configmap.yaml << 'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config
  namespace: elk-stack
data:
  filebeat.yml: |
    filebeat.inputs:
    - type: container
      paths:
        - /var/log/containers/*.log
      processors:
        - add_kubernetes_metadata:
            host: ${NODE_NAME}
            matchers:
            - logs_path:
                logs_path: "/var/log/containers/"
        - decode_json_fields:
            fields: ["message"]
            target: ""
            overwrite_keys: true
            
    output.elasticsearch:
      hosts: ["https://elasticsearch-es-http.elk-stack.svc.cluster.local:9200"]
      username: "admin"
      password: "Systex123!"
      ssl.verification_mode: "none"
      index: "filebeat-%{+yyyy.MM.dd}"
      timeout: 90
      
    setup.template.name: "filebeat"
    setup.template.pattern: "filebeat-*"
    setup.template.settings:
      index.number_of_shards: 1
      index.number_of_replicas: 0
      
    setup.ilm.enabled: false
    
    logging.level: info
    logging.to_stderr: true
    
    processors:
      - add_host_metadata:
          when.not.contains.tags: forwarded
      - add_kubernetes_metadata: ~
      
    http.enabled: true
    http.port: 5066
    
    monitoring.enabled: true
EOF

# 2. æ‡‰ç”¨ ConfigMap
kubectl apply -f filebeat-configmap.yaml

# 3. é©—è­‰é…ç½®
kubectl describe configmap filebeat-config -n elk-stack
```

### 5.3 éƒ¨ç½² Filebeat DaemonSet

```bash
# 1. å‰µå»º Filebeat DaemonSet
cat > filebeat-daemonset.yaml << 'EOF'
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: filebeat
  namespace: elk-stack
  labels:
    app: filebeat
spec:
  selector:
    matchLabels:
      app: filebeat
  template:
    metadata:
      labels:
        app: filebeat
    spec:
      serviceAccountName: filebeat
      terminationGracePeriodSeconds: 30
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: filebeat
        image: docker.elastic.co/beats/filebeat:8.5.1
        args: [
          "-c", "/etc/filebeat.yml",
          "-e"
        ]
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        securityContext:
          runAsUser: 0
          runAsGroup: 0
          privileged: true
        resources:
          limits:
            memory: 1Gi
            cpu: 1000m
          requests:
            cpu: 100m
            memory: 256Mi
        volumeMounts:
        - name: config
          mountPath: /etc/filebeat.yml
          readOnly: true
          subPath: filebeat.yml
        - name: data
          mountPath: /usr/share/filebeat/data
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: dockersock
          mountPath: /var/run/docker.sock
          readOnly: true
        livenessProbe:
          httpGet:
            path: /
            port: 5066
            scheme: HTTP
          failureThreshold: 5
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 5066
            scheme: HTTP
          failureThreshold: 3
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
      volumes:
      - name: config
        configMap:
          defaultMode: 0640
          name: filebeat-config
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: varlog
        hostPath:
          path: /var/log
      - name: dockersock
        hostPath:
          path: /var/run/docker.sock
      - name: data
        hostPath:
          path: /var/lib/filebeat-data
          type: DirectoryOrCreate
      tolerations:
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
EOF

# 2. éƒ¨ç½² DaemonSet
kubectl apply -f filebeat-daemonset.yaml

# 3. ç­‰å¾… Filebeat å°±ç·’
echo "ç­‰å¾… Filebeat Pod å•Ÿå‹•..."
sleep 60

# 4. æª¢æŸ¥ Filebeat ç‹€æ…‹
kubectl get daemonset filebeat -n elk-stack
kubectl get pods -l app=filebeat -n elk-stack -o wide

# 5. ç­‰å¾…æ‰€æœ‰ Pod å°±ç·’
kubectl wait --for=condition=ready pod -l app=filebeat -n elk-stack --timeout=300s || echo "éƒ¨åˆ† Pod å¯èƒ½ä»åœ¨å•Ÿå‹•ä¸­"
```

---

## ç¬¬6æ­¥ï¼šå‰µå»ºæ¸¬è©¦æ‡‰ç”¨

### 6.1 éƒ¨ç½²æ—¥èªŒç”Ÿæˆæ¸¬è©¦æ‡‰ç”¨

```bash
# 1. å‰µå»ºæ¸¬è©¦æ‡‰ç”¨
cat > test-log-apps.yaml << 'EOF'
# Web æ‡‰ç”¨æ¨¡æ“¬å™¨
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app-simulator
  namespace: elk-stack
  labels:
    app: web-app-simulator
spec:
  replicas: 2
  selector:
    matchLabels:
      app: web-app-simulator
  template:
    metadata:
      labels:
        app: web-app-simulator
        log-type: web
    spec:
      containers:
      - name: web-simulator
        image: busybox:1.35
        command:
        - sh
        - -c
        - |
          while true; do
            echo "$(date '+%Y-%m-%d %H:%M:%S') [INFO] Processing web request from IP: 192.168.1.$((RANDOM%255))"
            echo "$(date '+%Y-%m-%d %H:%M:%S') [INFO] Response time: ${RANDOM}ms"
            if [ $((RANDOM%10)) -eq 0 ]; then
              echo "$(date '+%Y-%m-%d %H:%M:%S') [ERROR] Database connection timeout"
            fi
            if [ $((RANDOM%20)) -eq 0 ]; then
              echo "$(date '+%Y-%m-%d %H:%M:%S') [WARN] High memory usage detected: $((60+RANDOM%40))%"
            fi
            sleep $((1+RANDOM%5))
          done
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
---
# API æ‡‰ç”¨æ¨¡æ“¬å™¨
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-service
  namespace: elk-stack
  labels:
    app: api-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: api-service
  template:
    metadata:
      labels:
        app: api-service
        log-type: api
    spec:
      containers:
      - name: api-service
        image: busybox:1.35
        command:
        - sh
        - -c
        - |
          while true; do
            ENDPOINTS=("users" "orders" "products" "payments" "analytics")
            ENDPOINT=${ENDPOINTS[$RANDOM % ${#ENDPOINTS[@]}]}
            STATUS_CODES=(200 200 200 404 500)
            STATUS=${STATUS_CODES[$RANDOM % ${#STATUS_CODES[@]}]}
            
            echo "{\"timestamp\":\"$(date -Iseconds)\", \"level\":\"INFO\", \"endpoint\":\"/api/v1/$ENDPOINT\", \"status\":$STATUS, \"response_time\":${RANDOM}}"
            
            if [ $((RANDOM%15)) -eq 0 ]; then
              echo "{\"timestamp\":\"$(date -Iseconds)\", \"level\":\"ERROR\", \"message\":\"Failed to connect to database\", \"error_code\":\"DB_CONN_001\"}"
            fi
            
            sleep $((2+RANDOM%8))
          done
        resources:
          requests:
            memory: "64Mi"
            cpu: "50m"
          limits:
            memory: "128Mi"
            cpu: "100m"
EOF

# 2. éƒ¨ç½²æ¸¬è©¦æ‡‰ç”¨
kubectl apply -f test-log-apps.yaml

# 3. ç­‰å¾…æ¸¬è©¦æ‡‰ç”¨å°±ç·’
kubectl wait --for=condition=ready pod -l app=web-app-simulator -n elk-stack --timeout=60s
kubectl wait --for=condition=ready pod -l app=api-service -n elk-stack --timeout=60s

# 4. æª¢æŸ¥æ¸¬è©¦æ‡‰ç”¨ç‹€æ…‹
kubectl get pods -n elk-stack | grep -E "(web-app|api-service)"
```

---

## ç¬¬7æ­¥ï¼šé…ç½®ç´¢å¼•ç”Ÿå‘½é€±æœŸç®¡ç†

### 7.1 è¨­ç½®ç´¢å¼•æ¸…ç†ç­–ç•¥

```bash
# 1. å‰µå»ºç´¢å¼•ç”Ÿå‘½é€±æœŸç®¡ç†ç­–ç•¥
cat > ilm-policy.json << 'EOF'
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "5GB",
            "max_age": "1d"
          }
        }
      },
      "warm": {
        "min_age": "2d",
        "actions": {
          "allocate": {
            "number_of_replicas": 0
          }
        }
      },
      "delete": {
        "min_age": "7d"
      }
    }
  }
}
EOF

# 2. æ‡‰ç”¨ ILM ç­–ç•¥
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -X PUT \
  "https://localhost:9200/_ilm/policy/filebeat-policy" \
  -H "Content-Type: application/json" \
  -u "admin:Systex123!" \
  -d @ilm-policy.json

# 3. å‰µå»ºç´¢å¼•æ¨¡æ¿
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -X PUT \
  "https://localhost:9200/_template/filebeat-template" \
  -H "Content-Type: application/json" \
  -u "admin:Systex123!" \
  -d '{
    "index_patterns": ["filebeat-*"],
    "settings": {
      "index.lifecycle.name": "filebeat-policy",
      "index.lifecycle.rollover_alias": "filebeat",
      "number_of_shards": 1,
      "number_of_replicas": 0
    }
  }'

# 4. æ¸…ç†è‡¨æ™‚æ–‡ä»¶
rm -f ilm-policy.json
```

---

## ç¬¬8æ­¥ï¼šé©—è­‰å’Œæ¸¬è©¦

### 8.1 å®Œæ•´ç³»çµ±é©—è­‰

```bash
echo "=== ELK Stack éƒ¨ç½²é©—è­‰ ==="

# 1. æª¢æŸ¥æ‰€æœ‰çµ„ä»¶ç‹€æ…‹
echo "1. æª¢æŸ¥æ‰€æœ‰ Pod ç‹€æ…‹:"
kubectl get pods -n elk-stack -o wide
echo ""

# 2. æª¢æŸ¥æœå‹™ç‹€æ…‹
echo "2. æª¢æŸ¥æœå‹™ç‹€æ…‹:"
kubectl get svc -n elk-stack
echo ""

# 3. æª¢æŸ¥ Elasticsearch å¥åº·ç‹€æ…‹
echo "3. æª¢æŸ¥ Elasticsearch å¥åº·:"
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -s -u "admin:Systex123!" \
  https://localhost:9200/_cluster/health?pretty
echo ""

# 4. æª¢æŸ¥ç´¢å¼•å‰µå»ºæƒ…æ³
echo "4. æª¢æŸ¥ Filebeat ç´¢å¼•:"
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -s -u "admin:Systex123!" \
  "https://localhost:9200/_cat/indices?v" | grep filebeat || echo "ç´¢å¼•å°šæœªå‰µå»ºï¼Œè«‹ç­‰å¾…..."
echo ""

# 5. æ¸¬è©¦ Kibana é€£æ¥
echo "5. æ¸¬è©¦ Kibana é€£æ¥:"
timeout 10 curl -k -I https://172.21.169.71:5601/login 2>/dev/null && echo "âœ… Kibana å¯è¨ªå•" || echo "âŒ Kibana é€£æ¥å¤±æ•—"
echo ""

# 6. æª¢æŸ¥æ¸¬è©¦æ‡‰ç”¨æ—¥èªŒ
echo "6. æª¢æŸ¥æ¸¬è©¦æ‡‰ç”¨æ—¥èªŒç”Ÿæˆ:"
kubectl logs -l app=web-app-simulator -n elk-stack --tail=3
echo ""

# 7. é¡¯ç¤ºç™»å…¥è³‡è¨Š
echo "=== ç™»å…¥è³‡è¨Š ==="
echo "Kibana URL: https://172.21.169.71:5601"
echo "Username: admin"
echo "Password: Systex123!"
echo ""
echo "Elasticsearch å…§éƒ¨é€£æ¥:"
echo "Host: elasticsearch-es-http.elk-stack.svc.cluster.local:9200"
echo "Username: admin"
echo "Password: Systex123!"
```

### 8.2 Kibana ç´¢å¼•æ¨¡å¼é…ç½®

```bash
# 1. ç­‰å¾…æ—¥èªŒæ”¶é›†ï¼ˆç´„2-3åˆ†é˜ï¼‰
echo "ç­‰å¾… Filebeat æ”¶é›†æ—¥èªŒä¸¦å»ºç«‹ç´¢å¼•..."
sleep 180

# 2. æª¢æŸ¥æ—¥èªŒç´¢å¼•å…§å®¹
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -s -u "admin:Systex123!" \
  "https://localhost:9200/filebeat-$(date +%Y.%m.%d)/_search?size=1&pretty" || echo "ç´¢å¼•æ•¸æ“šå°šæœªæº–å‚™å¥½"

# 3. é¡¯ç¤º Kibana é…ç½®èªªæ˜
echo ""
echo "=== Kibana é…ç½®èªªæ˜ ==="
echo "1. é–‹å•Ÿç€è¦½å™¨è¨ªå•: https://172.21.169.71:5601"
echo "2. ä½¿ç”¨å¸³è™Ÿç™»å…¥: admin / Systex123!"
echo "3. é€²å…¥ Stack Management > Data > Index Management"
echo "4. å‰µå»º Index Pattern: filebeat-*"
echo "5. è¨­å®šæ™‚é–“å­—æ®µ: @timestamp"
echo "6. é€²å…¥ Discover é é¢æŸ¥çœ‹æ—¥èªŒ"
```

### 8.3 æ•…éšœæ’é™¤æª¢æŸ¥

```bash
# 1. æª¢æŸ¥å¤±æ•—çš„ Pod
echo "=== æ•…éšœæ’é™¤æª¢æŸ¥ ==="
FAILED_PODS=$(kubectl get pods -n elk-stack --field-selector=status.phase!=Running -o name 2>/dev/null)
if [ -n "$FAILED_PODS" ]; then
    echo "ç™¼ç¾å¤±æ•—çš„ Pod:"
    echo "$FAILED_PODS"
    for pod in $FAILED_PODS; do
        echo "æª¢æŸ¥ Pod: $pod"
        kubectl describe $pod -n elk-stack
        kubectl logs $pod -n elk-stack --tail=20 2>/dev/null || echo "ç„¡æ³•å–å¾—æ—¥èªŒ"
    done
else
    echo "âœ… æ‰€æœ‰ Pod é‹è¡Œæ­£å¸¸"
fi

# 2. æª¢æŸ¥ Filebeat é€£æ¥
FILEBEAT_POD=$(kubectl get pods -n elk-stack -l app=filebeat -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
if [ -n "$FILEBEAT_POD" ]; then
    echo ""
    echo "æª¢æŸ¥ Filebeat ç‹€æ…‹:"
    kubectl exec $FILEBEAT_POD -n elk-stack -- curl -s http://localhost:5066 2>/dev/null | head -5 || echo "Filebeat æŒ‡æ¨™ç«¯é»ä¸å¯ç”¨"
fi

# 3. æª¢æŸ¥è³‡æºä½¿ç”¨
echo ""
echo "æª¢æŸ¥è³‡æºä½¿ç”¨æƒ…æ³:"
kubectl top pods -n elk-stack 2>/dev/null || echo "Metrics server ä¸å¯ç”¨"
```

---

## ç¬¬9æ­¥ï¼šç¶­è­·å’Œç›£æ§

### 9.1 æ—¥å¸¸ç›£æ§è…³æœ¬

```bash
# 1. å‰µå»ºç›£æ§è…³æœ¬
cat > monitor-elk-stack.sh << 'EOF'
#!/bin/bash
echo "=== ELK Stack ç›£æ§å ±å‘Š $(date) ==="
echo ""

# æª¢æŸ¥ Pod ç‹€æ…‹
echo "1. Pod ç‹€æ…‹æª¢æŸ¥:"
kubectl get pods -n elk-stack -o wide
echo ""

# æª¢æŸ¥æœå‹™ç‹€æ…‹
echo "2. æœå‹™ç‹€æ…‹æª¢æŸ¥:"
kubectl get svc -n elk-stack
echo ""

# æª¢æŸ¥ Elasticsearch å¥åº·
echo "3. Elasticsearch å¢é›†å¥åº·:"
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -s -u "admin:Systex123!" \
  https://localhost:9200/_cluster/health | jq . 2>/dev/null || echo "éœ€è¦å®‰è£ jq"
echo ""

# æª¢æŸ¥ç´¢å¼•å¤§å°
echo "4. ç´¢å¼•å¤§å°çµ±è¨ˆ:"
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -s -u "admin:Systex123!" \
  "https://localhost:9200/_cat/indices?v&h=index,docs.count,store.size" | head -10
echo ""

# æª¢æŸ¥ Filebeat ç‹€æ…‹
echo "5. Filebeat ç‹€æ…‹çµ±è¨ˆ:"
kubectl get pods -l app=filebeat -n elk-stack --no-headers | wc -l | xargs echo "é‹è¡Œä¸­çš„ Filebeat Pod æ•¸é‡:"
echo ""

echo "ç›£æ§å®Œæˆã€‚"
EOF

chmod +x monitor-elk-stack.sh
echo "ç›£æ§è…³æœ¬å·²å‰µå»º: ./monitor-elk-stack.sh"

# 2. åŸ·è¡Œä¸€æ¬¡ç›£æ§æª¢æŸ¥
# ./monitor-elk-stack.sh
```

### 9.2 å‚™ä»½ç­–ç•¥

```bash
# 1. å‰µå»º Elasticsearch å¿«ç…§å„²å­˜åº«è¨­ç½®
cat > backup-setup.json << 'EOF'
{
  "type": "fs",
  "settings": {
    "location": "/usr/share/elasticsearch/backup",
    "compress": true
  }
}
EOF

# 2. é…ç½®å¿«ç…§å„²å­˜åº«ï¼ˆå¯é¸ï¼‰
kubectl exec elasticsearch-es-master-0 -n elk-stack -- \
  curl -k -X PUT \
  "https://localhost:9200/_snapshot/backup_repo" \
  -H "Content-Type: application/json" \
  -u "admin:Systex123!" \
  -d @backup-setup.json 2>/dev/null || echo "å¿«ç…§è¨­ç½®éœ€è¦é¡å¤–çš„å­˜å„²é…ç½®"

rm -f backup-setup.json

echo "å‚™ä»½é…ç½®å®Œæˆï¼ˆå¦‚éœ€å•Ÿç”¨ï¼Œè«‹é…ç½®æŒä¹…åŒ–å­˜å„²ï¼‰"
```

---

## æ¸…ç†å’Œé‡æ–°éƒ¨ç½²

### å®Œå…¨æ¸…ç†å‘½ä»¤

```bash
# âš ï¸ è­¦å‘Šï¼šä»¥ä¸‹å‘½ä»¤å°‡å®Œå…¨åˆªé™¤ ELK Stack éƒ¨ç½²ï¼

# 1. åˆªé™¤æ‰€æœ‰æ‡‰ç”¨
kubectl delete namespace elk-stack --force --grace-period=0

# 2. æ¸…ç† RBAC
kubectl delete clusterrole filebeat
kubectl delete clusterrolebinding filebeat

# 3. æ¸…ç† MetalLB é…ç½®
kubectl delete ipaddresspool kibana-pool -n metallb-system
kubectl delete l2advertisement kibana-advertisement -n metallb-system

# 4. æ¸…ç† ECK Operatorï¼ˆå¦‚éœ€è¦ï¼‰
# kubectl delete namespace elastic-system

echo "ELK Stack å·²å®Œå…¨æ¸…ç†"
```

---

## æˆåŠŸæ¨™æº–

### éƒ¨ç½²æˆåŠŸæŒ‡æ¨™

âœ… **Elasticsearch**: `1/1 Running`, å¢é›†ç‹€æ…‹ `green`  
âœ… **Kibana**: `1/1 Running`, å¯é€šé https://172.21.169.71:5601 è¨ªå•  
âœ… **Filebeat**: æ‰€æœ‰ç¯€é»ä¸Š `1/1 Running`  
âœ… **èªè­‰**: å¯ä½¿ç”¨ `admin/Systex123!` ç™»å…¥  
âœ… **æ—¥èªŒæ”¶é›†**: Elasticsearch ä¸­èƒ½çœ‹åˆ° `filebeat-*` ç´¢å¼•  
âœ… **æ¸¬è©¦æ‡‰ç”¨**: ç”¢ç”Ÿæ—¥èªŒä¸¦è¢«æ­£ç¢ºæ”¶é›†  

### è¨ªå•è³‡è¨Šç¸½çµ

```
ğŸŒ Kibana Web Interface
   URL: https://172.21.169.71:5601
   Username: admin  
   Password: Systex123!

ğŸ” Elasticsearch API
   Internal: https://elasticsearch-es-http.elk-stack.svc.cluster.local:9200
   Username: admin
   Password: Systex123!

ğŸ“Š æ—¥èªŒç´¢å¼•æ¨¡å¼
   Pattern: filebeat-*
   æ™‚é–“å­—æ®µ: @timestamp

ğŸ¯ æ¸¬è©¦æ‡‰ç”¨æ—¥èªŒ
   Namespace: elk-stack
   æ‡‰ç”¨: web-app-simulator, api-service
```

---

**ğŸ‰ éƒ¨ç½²å®Œæˆï¼**

ä½ ç¾åœ¨æ“æœ‰ä¸€å€‹å®Œæ•´çš„ã€çµ±ä¸€éƒ¨ç½²åœ¨ `elk-stack` namespace çš„ ELK Stack ç³»çµ±ï¼ŒåŒ…å«ï¼š
- **å®‰å…¨çš„ HTTPS è¨ªå•**
- **çµ±ä¸€çš„ admin å¸³è™Ÿèªè­‰**  
- **è‡ªå‹•æ—¥èªŒæ”¶é›†å’Œç´¢å¼•**
- **æ¸¬è©¦æ‡‰ç”¨å’Œç›£æ§å·¥å…·**
- **ç”Ÿç”¢ç´šåˆ¥çš„é…ç½®å’Œå„ªåŒ–**

å¯ä»¥é–‹å§‹ä½¿ç”¨ Kibana é€²è¡Œæ—¥èªŒåˆ†æå’Œè¦–è¦ºåŒ–äº†ï¼